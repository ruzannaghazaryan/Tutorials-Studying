{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b265a08f",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71345046",
   "metadata": {},
   "source": [
    "__Columns with different ranges__\n",
    "\n",
    "annual income ($$70000, 60000, 52000)\n",
    "\n",
    "age (45years, 44, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7c41c",
   "metadata": {},
   "source": [
    "What can happen with unscaled features is that the unit values of one column can be so much larger than the unit values of the other that it might overpower.\n",
    "<br>So we might make the erroneous conclusion that, okay, we're going to ignore values 1 and 4 because those are such small differences compared to 10.000 and 8.000, we're gonna focus on these large of magnitude numbers, 10.000 and 8.000.\n",
    "\n",
    "And that's why __we need to normalize variables because we can't compare__.\n",
    "<br>Right now, we're comparing salaries to years, it's like comparing apples and oranges. These are non-comparable things.\n",
    "\n",
    "And even if you have the same units of measurement, like dollars and dollars in two columns, they still might not be comparable\n",
    "because they're relating to different things.\n",
    "\n",
    "So it's important to scale your features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bbcdab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57573c",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8316877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#pyplot module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68fe33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db451428",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c134c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b142593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fd7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features and the dependent variable vector\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e67e66",
   "metadata": {},
   "source": [
    "A very important principle in Python which you must absolutely know,\n",
    "a __range__ in Python __includes the lower bound__, but __excludes the upper bound__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bd6e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary\n",
       "0   France  44.0  72000.0\n",
       "1    Spain  27.0  48000.0\n",
       "2  Germany  30.0  54000.0\n",
       "3    Spain  38.0  61000.0\n",
       "4  Germany  40.0      NaN\n",
       "5   France  35.0  58000.0\n",
       "6    Spain   NaN  52000.0\n",
       "7   France  48.0  79000.0\n",
       "8  Germany  50.0  83000.0\n",
       "9   France  37.0  67000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, :-1]\n",
    "# now it's still a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040e0cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need arrays\n",
    "df.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4722406e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ff1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1423a77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e9bcbf",
   "metadata": {},
   "source": [
    "## Object-oriented programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a3171",
   "metadata": {},
   "source": [
    "A __class__ is the model, or a blueprint, of something we want to build. For example, if we make a house construction plan that gathers the instructions on how to build a house, then this construction plan is the class.\n",
    "\n",
    "An __object__ is an instance of the class. So if we take that same example of the house construction plan, then an object is simply a house. A house (the object) that was built by following the instructions of the construction plan (the class).\n",
    "And therefore there can be many objects of the same class, because we can build many houses from the construction plan.\n",
    "\n",
    "A __method__ is a tool we can use on the object to complete a specific action. So in this same example, a tool can be to open the main door of the house if a guest is coming. A method can also be seen as a function that is applied onto the object, takes some inputs (that were defined in the class) and returns some output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bea912",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306885c",
   "metadata": {},
   "source": [
    "## Taking care of Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4d107d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae4995",
   "metadata": {},
   "source": [
    "There are actually several ways __to handle missing values__.\n",
    "\n",
    "- __The first way__ is to just ignore the observation __by deleting it__. (and this actually works if you have a large data set, and only 1% missing data, you know removing 1% of the observations won't change much the learning quality of your model)\n",
    "- __The second way__ is to replace the missing value by __the average__ of all the values in the column, in which the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e87714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to access a module, we have to add a dot (sklearn.), because actually this SimpleImputer class \n",
    "# which we want to import, belongs to a certain module of scikit-learn called impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa895c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the class that we're gonna use from sklearn, is called SimpleImputer.\n",
    "\n",
    "# first import the class,\n",
    "# then create an instance, an object of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ab503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute - приписывать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45e816d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# replace all the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fccdff",
   "metadata": {},
   "source": [
    "There are actually many replacements that you could do (instead of replacing it by the average salary, replace it by the median salary. By the most frequent value for categories).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9b8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this imputer object on the matrix of features (only for numerical columns)\n",
    "imputer.fit(X[:, 1:3])\n",
    "# to do the transformation\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed4e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355277b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75d733",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3b676",
   "metadata": {},
   "source": [
    "This data set contains one column with categories - France, Spain, or Germany.\n",
    "<br>It'll be difficult for machine learning model to compute some correlations between these columns (the features) and the outcome. And therefore, we'll have to __turn__ these strings, these __categories into numbers__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbd54f",
   "metadata": {},
   "source": [
    "So one idea would be to encode France into zero, Spain into one, and Germany into two. However, if we do this, our future ML model could understand that there is a numerical order between these three countries and this order matters whereas of course it is absolutely not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acfb8443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'France', 'Germany', 'Spain'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd25b4",
   "metadata": {},
   "source": [
    "Another way is __One-Hot Encoding__ (consists of creating binary vectors).\n",
    "<br>France - the vector 1 0 0\n",
    "<br>Spain - the vector 0 1 0\n",
    "<br>Germany - the vector 0 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934264ae",
   "metadata": {},
   "source": [
    "To replace the dependent variable by zeros and ones. And that's totally fine for the dependent variable as long as it is a binary outcome. It will actually not compromise the future accuracy of the model if you just replace no and yes by zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a02837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f1048",
   "metadata": {},
   "source": [
    "__encoding the independent variable__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5890cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "# remainder='passthrough' means we want to keep the columns that won't be applied some transformation, \n",
    "# that won't be one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dba68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ct.fit_transform(X)\n",
    "# the result should be an array (if it's not, then make it by using np.array(), as it will be expected\n",
    "# by the future ML models which we're gonna build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "684731c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # country column in three binary column-vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed04688",
   "metadata": {},
   "source": [
    "__encoding the dependent variable__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e34e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1940501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cba657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98077d57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c745062",
   "metadata": {},
   "source": [
    "## Splitting the dataset into Training set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54aac5",
   "metadata": {},
   "source": [
    "### !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc9567",
   "metadata": {},
   "source": [
    "We have to apply __feature scaling after splitting__ the data set \n",
    "into the training set and the test set. \n",
    "\n",
    "Why?\n",
    "<br>Because the test set\n",
    "is something you're not supposed to work with\n",
    "for the training. And feature scaling is\n",
    "a technique that will get the mean\n",
    "and the standard deviation of your feature.\n",
    "So, if we apply feature scaling before the split\n",
    "then it will actually get the mean\n",
    "and the standard deviation of all the values,\n",
    "including the ones in the test set.\n",
    "And since the test set is\n",
    "something you're not supposed to have,\n",
    "applying feature scaling on the original data set,\n",
    "before the split,\n",
    "would cause some what we call __information leakage__\n",
    "on the test set.\n",
    "You know, we would grab some information from the test set,\n",
    "which we're not supposed to get.\n",
    "\n",
    "__to prevent information leakage on the test set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adfc1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37ffeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# random_state parameter - so that we can have the same results displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ca8f585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f989b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc32c21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35b94de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fdeb93",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630db7c",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78538618",
   "metadata": {},
   "source": [
    "It will allow to put all our features on the same scale.\n",
    "\n",
    "You also need to be aware that we won't have to apply feature scaling for all the ML models, just for some of them.\n",
    "\n",
    "Now the question is much asked by the data science community.\n",
    "<br>__Should we go for standardization or normalization?__\n",
    "\n",
    "- __Normalization__ is recommended when you have __a normal distribution__ in most of your __features__.\n",
    "- __Standardization__ actually works well all the time. It will do the job all the time.\n",
    "\n",
    "We won't apply feature scaling on the whole matrix of features X,\n",
    "but of course on both X-train and X-test separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f452ea",
   "metadata": {},
   "source": [
    "__Performing standardization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2e2ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "788cec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f324d3",
   "metadata": {},
   "source": [
    "__!!! one of the most frequently asked questions in the data science community__\n",
    "<br>Do we have to apply feature scaling - standardization to the dummy variables in the matrix of features?\n",
    "\n",
    "The answer is no, because the goal of standardization or feature scaling in general, it is to have all the values of the features in the same range.\n",
    "- And since standardization actually transforms your features so that they take values between more or less\n",
    "minus three and plus three, while since here our dummy variables already take values between minus three and plus three\n",
    "because they're equal to either one or zero.\n",
    "-Well, there is nothing extra to be done here with standardization.\n",
    "And actually, standardization will only make it worse\n",
    "because indeed it will still transform these values\n",
    "between minus three and plus three.\n",
    "But then you will totally lose the interpretation\n",
    "of these variables.\n",
    "In other words, you will lose the information of\n",
    "which country corresponds to the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "573ad06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we won't apply feature scaling on the dummy variables\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777cb6d",
   "metadata": {},
   "source": [
    "- __.fit() method__ will only compute the mean and the standard deviation of the values.\n",
    "- And then you have the __.transform() method__ that will indeed\n",
    "apply this formula by transforming each\n",
    "of the values here.\n",
    "- One of the methods of the StandardScaler class is actually __.fit_transform() method__, which\n",
    "of course will proceed to the two tools at the same time.\n",
    "-  I will __only__ apply the __.transform() method__\n",
    "because indeed the features of __the test set__\n",
    "need to be scaled by the same scaler\n",
    "that was used on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6aa5d478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, -0.19159184384578545, -1.0781259408412425],\n",
       "       [0.0, 1.0, 0.0, -0.014117293757057777, -0.07013167641635372],\n",
       "       [1.0, 0.0, 0.0, 0.566708506533324, 0.633562432710455],\n",
       "       [0.0, 0.0, 1.0, -0.30453019390224867, -0.30786617274297867],\n",
       "       [0.0, 0.0, 1.0, -1.9018011447007988, -1.420463615551582],\n",
       "       [1.0, 0.0, 0.0, 1.1475343068237058, 1.232653363453549],\n",
       "       [0.0, 1.0, 0.0, 1.4379472069688968, 1.5749910381638885],\n",
       "       [1.0, 0.0, 0.0, -0.7401495441200351, -0.5646194287757332]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41bc6b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, -1.4661817944830124, -0.9069571034860727],\n",
       "       [1.0, 0.0, 0.0, -0.44973664397484414, 0.2056403393225306]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c95ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
