{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b477b482",
   "metadata": {},
   "source": [
    "As I explained in the previous tutorial, Backward Elimination is irrelevant in Python, because __the Scikit-Learn library automatically takes care of selecting the statistically significant features__ when training the model to make accurate predictions.\n",
    "\n",
    "However, if you do really want to learn __how to manually implement Backward Elimination in Python__ and identify the most statistically significant features, please find in this link below some old videos I made on how to implement Backward Elimination in Python:\n",
    "\n",
    "https://www.dropbox.com/sh/pknk0g9yu4z06u7/AADSTzieYEMfs1HHxKHt9j1ba?dl=0\n",
    "\n",
    "These are old videos made on Spyder but the dataset and the code are the same as in the previous video lectures of this section on Multiple Linear Regression, except that I had manually removed the first column to avoid the Dummy Variable Trap with this line of code:\n",
    "\n",
    "#### Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "Just keep this for this Backward Elimination implementation, but keep in mind that in general you don't have to remove manually a dummy variable column because Scikit-Learn takes care of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc5878",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07dd0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac655ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 0.0 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [0.0 135426.92 0.0 'California']\n",
      " [542.05 51743.15 0.0 'New York']\n",
      " [0.0 116983.8 45173.06 'California']]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "880740be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "525731f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c90c7e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Multiple Linear Regression model on the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94084cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67afbae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42467.52924854249"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2168f119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.66e+01, -8.73e+02,  7.86e+02,  7.73e-01,  3.29e-02,  3.66e-02])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0ca26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969967e7",
   "metadata": {},
   "source": [
    "## Building the optimal model using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf4fe395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = b0 + b1 * x1 + b2 * x2 + b3 * x3 + ... + bn * xn\n",
    "\n",
    "# b0 - is a constant, but we don't have associated independent x0, which actually x0 = 1\n",
    "# b0 * x0, where x0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37f46266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoiding the dummy variable trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "beb97820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14285f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81efdfdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# or\n",
    "\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c1e6c",
   "metadata": {},
   "source": [
    "the vector of 1s should be the first column of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54e4afe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d3f8841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0c08a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting significance level, SL = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9eecd8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 0.00e+00, 1.00e+00, 1.65e+05, 1.37e+05, 4.72e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 1.63e+05, 1.51e+05, 4.44e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.53e+05, 1.01e+05, 4.08e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.44e+05, 1.19e+05, 3.83e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.42e+05, 9.14e+04, 3.66e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.32e+05, 9.98e+04, 3.63e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 1.35e+05, 1.47e+05, 1.28e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.30e+05, 1.46e+05, 3.24e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.21e+05, 1.49e+05, 3.12e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 1.23e+05, 1.09e+05, 3.05e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.02e+05, 1.11e+05, 2.29e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 1.01e+05, 9.18e+04, 2.50e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 9.39e+04, 1.27e+05, 2.50e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 9.20e+04, 1.35e+05, 2.53e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.20e+05, 1.57e+05, 2.57e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.15e+05, 1.23e+05, 2.62e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 7.80e+04, 1.22e+05, 2.64e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 9.47e+04, 1.45e+05, 2.83e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 9.17e+04, 1.14e+05, 2.95e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 8.64e+04, 1.54e+05, 0.00e+00],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 7.63e+04, 1.14e+05, 2.99e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 7.84e+04, 1.54e+05, 3.00e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 7.40e+04, 1.23e+05, 3.03e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 6.75e+04, 1.06e+05, 3.05e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 7.70e+04, 9.93e+04, 1.41e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 6.47e+04, 1.40e+05, 1.38e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 7.53e+04, 1.44e+05, 1.34e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 7.21e+04, 1.28e+05, 3.53e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 6.61e+04, 1.83e+05, 1.18e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 6.56e+04, 1.53e+05, 1.07e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 6.20e+04, 1.16e+05, 9.11e+04],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 6.11e+04, 1.53e+05, 8.82e+04],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 6.34e+04, 1.29e+05, 4.61e+04],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 5.55e+04, 1.03e+05, 2.15e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 4.64e+04, 1.58e+05, 2.11e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 4.60e+04, 8.50e+04, 2.06e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 2.87e+04, 1.27e+05, 2.01e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 4.41e+04, 5.13e+04, 1.97e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 2.02e+04, 6.59e+04, 1.85e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 3.86e+04, 8.30e+04, 1.75e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 2.88e+04, 1.19e+05, 1.73e+05],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 2.79e+04, 8.47e+04, 1.64e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 2.36e+04, 9.62e+04, 1.48e+05],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.55e+04, 1.27e+05, 3.55e+04],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 2.22e+04, 1.55e+05, 2.83e+04],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 1.00e+03, 1.24e+05, 1.90e+03],\n",
       "       [1.00e+00, 1.00e+00, 0.00e+00, 1.32e+03, 1.16e+05, 2.97e+05],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.35e+05, 0.00e+00],\n",
       "       [1.00e+00, 0.00e+00, 1.00e+00, 5.42e+02, 5.17e+04, 0.00e+00],\n",
       "       [1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.17e+05, 4.52e+04]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the full model with all possible predictors\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fdcf4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:44:51</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Thu, 22 Dec 2022   Prob (F-statistic):           1.34e-27\n",
       "Time:                        23:44:51   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa84af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:47:09</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Thu, 22 Dec 2022   Prob (F-statistic):           8.49e-29\n",
       "Time:                        23:47:09   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P_value has x2 variable, so let's drop it\n",
    "\n",
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d9541a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:56:23</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Thu, 22 Dec 2022   Prob (F-statistic):           4.53e-30\n",
       "Time:                        23:56:23   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x1 variable\n",
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7c718f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:58:02</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Thu, 22 Dec 2022   Prob (F-statistic):           2.16e-31\n",
       "Time:                        23:58:02   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 5]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2aa472bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:58:27</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Thu, 22 Dec 2022   Prob (F-statistic):           3.50e-32\n",
       "Time:                        23:58:27   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3]]\n",
    "X_opt = X_opt.astype(np.float64)\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f121172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49032.89914125211"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary2().tables[1]['Coef.']['const']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "feee46e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42467.52924854249"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59a55a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3f33a",
   "metadata": {},
   "source": [
    "__Question 1:__ How do I use my multiple linear regression model to make a single prediction, for example, the profit of a startup with R&D Spend = 160000, Administration Spend = 130000, Marketing Spend = 300000 and State = California?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60fe9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181566.92]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.predict([[1, 0, 0, 160000, 130000, 300000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7494f",
   "metadata": {},
   "source": [
    "__Important note 1:__ Notice that the values of the features were all input in __a double pair of square brackets__. That's because the __\"predict\" method always expects a 2D array__ as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array. Simply put:\n",
    "\n",
    "1,0,0,160000,130000,300000scalars \n",
    "\n",
    "[1,0,0,160000,130000,300000]1D array \n",
    "\n",
    "[[1,0,0,160000,130000,300000]]2D array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5df7d",
   "metadata": {},
   "source": [
    "__Important note 2:__ Notice also that the \"California\" state was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the second row of the matrix of features X, \"California\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, not the last three ones, because the __dummy variables are always created in the first columns__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36715e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f922806",
   "metadata": {},
   "source": [
    "__Question 2:__ How do I get the final regression equation y = b0 + b1 x1 + b2 x2 + ... with the final values of the coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f21316",
   "metadata": {},
   "source": [
    "### Getting the final linear regression equation with the values of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a210d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42467.52924854249\n"
     ]
    }
   ],
   "source": [
    "print(regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10cbfb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.66e+01 -8.73e+02  7.86e+02  7.73e-01  3.29e-02  3.66e-02]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b5736",
   "metadata": {},
   "source": [
    "Therefore, the equation of our multiple linear regression model is:\n",
    "\n",
    "__Profit=86.6Dummy State 1873Dummy State 2+786Dummy State 3+0.773R&D Spend+0.0329Administration+0.0366Marketing Spend+42467.53__\n",
    "\n",
    "Important Note: To get these coefficients we called the __\"coef_\"__ and __\"intercept_\" attributes__ from our regressor object. Attributes in Python are different than methods and usually return a simple value or an array of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb8d67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bb777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
